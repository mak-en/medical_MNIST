{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_file.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDid9UDBj9aFd0UQSpmL3J"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZAhpo9y3FvL"
      },
      "source": [
        "# Download data\n",
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d 'andrewmvd/medical-mnist'\n",
        "!unzip -q medical-mnist.zip -d data\n",
        "!rm medical-mnist.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSOXj_vP9Vj_"
      },
      "source": [
        "# Installations\n",
        "!pip install pytorch-lightning\n",
        "# !pip install torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA6ynB7HTXdR"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_lightning.core.lightning import LightningModule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P-c3p3rKjPZ"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "class MedicalDataMNIST(pl.LightningDataModule):\n",
        "    def __init__(self, num_workers=1):\n",
        "      super().__init__()\n",
        "      self.num_workers = num_workers\n",
        "      self.labels_map = {0 : \"AbdomenCT\",\n",
        "                         1 : \"BreastMRI\",\n",
        "                         2 : \"CXR\",\n",
        "                         3 : \"ChestCT\",\n",
        "                         4 : \"Hand\",\n",
        "                         5 : \"HeadCT\"}\n",
        "      self.train_transform = transforms.Compose([transforms.ColorJitter(hue=.20, saturation=.20),\n",
        "                                                 transforms.RandomHorizontalFlip(),\n",
        "                                                 transforms.RandomVerticalFlip(),\n",
        "                                                 transforms.RandomRotation(10),\n",
        "                                                 transforms.ToTensor(),\n",
        "                                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                                      std=[0.229, 0.224, 0.225])])\n",
        "      \n",
        "      self.val_test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                                         std=[0.229, 0.224, 0.225])])\n",
        "      \n",
        "\n",
        "    def prepare_data(self):\n",
        "      pass\n",
        "      # called only on 1 GPU\n",
        "      # ONLY DOWNLOAD!!!\n",
        "      \n",
        "    def setup(self, stage=None):\n",
        "\n",
        "      self.dataset = ImageFolder(\"./data/\")\n",
        "      train_size = int(0.7 * len(self.dataset)) # take 70% for training\n",
        "      val_size = int(0.2 * len(self.dataset)) # take 20% for validation\n",
        "      test_size = len(self.dataset) - (train_size + val_size) # take 10% for test\n",
        "      \n",
        "      self.train_set, self.val_set, self.test_set = torch.utils.data.random_split(self.dataset, [train_size, val_size, test_size])\n",
        "\n",
        "      self.train_set.dataset.transform = self.train_transform\n",
        "      self.val_set.dataset.transform = self.val_test_transform\n",
        "      self.test_set.dataset.transform = self.val_test_transform\n",
        "\n",
        "    def train_dataloader(self):\n",
        "      return DataLoader(self.train_set, batch_size=128, shuffle=True, num_workers=self.num_workers) # 128 batch_size is max\n",
        "\n",
        "    def val_dataloader(self):\n",
        "      return DataLoader(self.val_set, batch_size=128, num_workers=self.num_workers)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "      print(\"TEST DATALOADER\")\n",
        "      return DataLoader(self.test_set, batch_size=128, num_workers=self.num_workers)\n",
        "\n",
        "    def visualize_dataset(self):\n",
        "      # Visualizes dataset\n",
        "      figure = plt.figure(figsize=(8, 8))\n",
        "      cols, rows = 3, 3\n",
        "      for i in range(1, cols * rows + 1):\n",
        "          sample_idx = torch.randint(len(self.train_set), size=(1,)).item()\n",
        "          norm_img, label = self.train_set[sample_idx]\n",
        "          mean = torch.tensor([0.485, 0.456, 0.406])\n",
        "          std = torch.tensor([0.229, 0.224, 0.225])\n",
        "          img = norm_img * std[:, None, None] + mean[:, None, None] \n",
        "          figure.add_subplot(rows, cols, i)\n",
        "          plt.title(self.labels_map[label])\n",
        "          plt.axis(\"off\")\n",
        "          plt.imshow(img.permute(1, 2, 0))\n",
        "      plt.show()\n",
        "\n",
        "    def visualize_dataloader(self):\n",
        "      # Display image and label\n",
        "      train_dataloader = self.train_dataloader()\n",
        "      train_features, train_labels = next(iter(train_dataloader))\n",
        "      print(f\"Feature batch shape: {train_features.size()}\")\n",
        "      print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "      norm_img = train_features[0]\n",
        "      mean = torch.tensor([0.485, 0.456, 0.406])\n",
        "      std = torch.tensor([0.229, 0.224, 0.225])\n",
        "      img = norm_img * std[:, None, None] + mean[:, None, None]\n",
        "      label = train_labels[0]\n",
        "      plt.imshow(img.permute(1, 2, 0))\n",
        "      plt.show()\n",
        "      print(f\"Label: {self.labels_map[label.item()]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZsfSpK17vhE"
      },
      "source": [
        "dm = MedicalDataMNIST()\n",
        "dm.setup()\n",
        "dm.visualize_dataset()\n",
        "dm.visualize_dataloader()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sihoHTSWNoPA"
      },
      "source": [
        "# Creating model\n",
        "\n",
        "class MedicalMNIST(LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = models.efficientnet_b7(pretrained=True)\n",
        "        self.model.classifier = torch.nn.Sequential(torch.nn.Dropout(p=0.2, inplace=False),\n",
        "                                                    torch.nn.Linear(in_features=self.model.classifier[1].in_features, out_features=6))\n",
        "        # num_ftrs = self.model.fc.in_features\n",
        "        # self.model.fc = torch.nn.Linear(num_ftrs, 6)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self.model(x)\n",
        "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.model(x)\n",
        "        loss = torch.nn.functional.cross_entropy(y_hat, y)\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN\n",
        "# Number of cpus and gpus\n",
        "NUM_DATALOADER_WORKERS = os.cpu_count()\n",
        "print(f\"Number of cpus: {NUM_DATALOADER_WORKERS}\")\n",
        "NUM_GPUS = torch.cuda.device_count() if torch.cuda.is_available() else None\n",
        "print(f\"Number of gpus: {NUM_GPUS}\")\n",
        "\n",
        "# Train\n",
        "medical_mnist_data = MedicalDataMNIST(num_workers=NUM_DATALOADER_WORKERS)\n",
        "# medical_mnist_data.setup()\n",
        "model = MedicalMNIST()\n",
        "trainer = Trainer(gpus=NUM_GPUS, max_epochs=4)\n",
        "trainer.fit(model, datamodule=medical_mnist_data)"
      ],
      "metadata": {
        "id": "RJcdFyj8sGg1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}