{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_file.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMa/euELiObHxwGhhK9jXsg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZAhpo9y3FvL"
      },
      "source": [
        "# Download data\n",
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d 'andrewmvd/medical-mnist'\n",
        "!unzip -q medical-mnist.zip -d data\n",
        "!rm medical-mnist.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA6ynB7HTXdR"
      },
      "source": [
        "# Imports\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P-c3p3rKjPZ"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "lass MyDataModule(LightningDataModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # self.train_dims = None\n",
        "        # self.vocab_size = 0\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # called only on 1 GPU\n",
        "        self.dataset = torchvision.datasets.Imagefolder('.\\data\\')\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None):\n",
        "        # called on every GPU\n",
        "        # vocab = load_vocab()\n",
        "        # self.vocab_size = len(vocab)\n",
        "        test_size = 0.1 * len(dataset)\n",
        "        self.test_set = torch.utils.data.Subset(self.dataset, range(test_size))  # take 10% for test\n",
        "        self.train_set = torch.utils.data.Subset(self.dataset, range(test_size, len(dataset)) # the last part for train\n",
        "\n",
        "    # def train_dataloader(self):\n",
        "    #     transforms = ...\n",
        "    #     return DataLoader(self.train, batch_size=64)\n",
        "\n",
        "    # def val_dataloader(self):\n",
        "    #     transforms = ...\n",
        "    #     return DataLoader(self.val, batch_size=64)\n",
        "\n",
        "    # def test_dataloader(self):\n",
        "    #     transforms = ...\n",
        "    #     return DataLoader(self.test, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}